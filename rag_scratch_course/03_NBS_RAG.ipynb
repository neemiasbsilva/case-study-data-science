{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN56J31ACluanCtN78d96bN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG From scratch: Routing\n",
        "\n",
        "## Purpose\n",
        "\n",
        "This notebook has the purpose to explain Routing. Routing refers to the process of directing queries or tasks to the most appropriate components, resources, or subsystems in a pipeline.\n",
        "\n",
        "- Logical Routing and Semantic Routing\n",
        "    - Let LLM choose DB based on the question.\n",
        "    - Embed question and choose prompt based on similarity\n",
        "    - [Routing to Multiple Index](https://python.langchain.com/docs/use_cases/query_analysis/techniques/routing#routing-to-multiple-indexes)"
      ],
      "metadata": {
        "id": "0Q8UGA9WOS2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment\n",
        "\n",
        "`(1) Packages`"
      ],
      "metadata": {
        "id": "MnDE0P74O4SQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X_xnmTeuOI3E"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community langchain_openai langchainhub langchain -q\n",
        "!pip install tiktoken chromadb -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`(2) LangSmith`"
      ],
      "metadata": {
        "id": "3wpZ4NsFPOQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
      ],
      "metadata": {
        "id": "MeR4ONLTrQ1P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "if api_key:\n",
        "    os.environ[\"LANGCHAIN_API_KEY\"] = api_key\n",
        "else:\n",
        "    api_key = input(\"Enter your API key: \")\n",
        "    os.environ[\"LANGCHAIN_API_KEY\"] = api_key"
      ],
      "metadata": {
        "id": "9Vk7sMmz627L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`(3) API Keys`"
      ],
      "metadata": {
        "id": "WoAoJKVysTvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "    api_key = input(\"Enter your API key: \")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "else:\n",
        "    api_key = input(\"Enter your API key: \")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key"
      ],
      "metadata": {
        "id": "avf4vmga7S0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logical and Semantic Routing\n",
        "\n",
        "Here we will use function-calling for classification."
      ],
      "metadata": {
        "id": "tVEuB8TTQWkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_pBd1KGrFUz",
        "outputId": "b37f6c16-463b-42fa-f80c-98c4efbd9e3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data model\n",
        "class RouteQuery(BaseModel):\n",
        "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
        "    datasource: Literal[\"python_docs\", \"js_docs\", \"golang_docs\"] = Field(\n",
        "        ...,\n",
        "        description=\"Given a user question choose which datasource would be most \\\n",
        "        relevant for answering their question\"\n",
        "    )\n",
        "\n",
        "# LLM with function call\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
        "structured_llm = llm.with_structured_output(RouteQuery)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are an expert at routing a user question to the appropriate\n",
        "data source. Based on the programming language the question is referring to,\n",
        "route it to the relevant data source.\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define router\n",
        "router = prompt | structured_llm"
      ],
      "metadata": {
        "id": "c9FhUiIErVEE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** was used function calling to produce structure output."
      ],
      "metadata": {
        "id": "Aq-d9RG9swgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"Why doesn't the following code work:\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"])\n",
        "prompt.invoke(\"french\")\n",
        "\"\"\"\n",
        "\n",
        "result = router.invoke(\n",
        "    {\n",
        "        \"question\": question\n",
        "    }\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxXoBEC4sv4P",
        "outputId": "4372b919-8dc8-40fa-f860-15dcd686a1d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RouteQuery(datasource='python_docs')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.datasource"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "Jp8GCHi4sro2",
        "outputId": "94f5da0a-31dd-45a2-fafc-924c1cbe38c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'python_docs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have this, it is trivial to define a branch that uses `result.datasource`"
      ],
      "metadata": {
        "id": "KArMBuy7u0Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_route(result):\n",
        "    if \"python_docs\" in result.datasource.lower():\n",
        "        # Logic here\n",
        "        return \"chain for python docs\"\n",
        "    elif \"js_docs\" in result.datasource.lower():\n",
        "        # Logic here\n",
        "        return \"chain for js docs\"\n",
        "    elif \"golang_docs\" in result.datasource.lower():\n",
        "        # Logic here\n",
        "        return \"chain for golang docs\"\n",
        "\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "full_chain = (\n",
        "    router\n",
        "    | RunnableLambda(choose_route)\n",
        ")\n",
        "\n",
        "full_chain.invoke(\n",
        "    {\n",
        "        \"question\": question\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "oNCJmXGzuxtg",
        "outputId": "c03868bc-6df0-4fa5-b9b1-536f67ff5627"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chain for python docs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semantic Routing"
      ],
      "metadata": {
        "id": "coURiMnZvaWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utils.math import cosine_similarity\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n"
      ],
      "metadata": {
        "id": "TY-6g38lvVX9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Two prompts\n",
        "physics_template = \"\"\"You are a very smart physics professor. \\\n",
        "You are great at answering questions about physics in a concise and easy to\n",
        "understand manner. \\\n",
        "When you don't know the answer to a question you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{query}\n",
        "\"\"\"\n",
        "\n",
        "math_template = \"\"\"You are very good mathematician. You are great at answering math questions. \\\n",
        "You are so good because you are able to break down hard problems into their component parts, \\\n",
        "answer the component parts, and then put them together to answer the broader question.\n",
        "\n",
        "Here is a question:\n",
        "{query}\n",
        "\"\"\"\n",
        "\n",
        "# Embed prompts\n",
        "embeddings = OpenAIEmbeddings()\n",
        "prompt_templates = [physics_template, math_template]\n",
        "prompt_embeddings = embeddings.embed_documents(prompt_templates)"
      ],
      "metadata": {
        "id": "ie0v1UnUwXUq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Route question to prompt\n",
        "def prompt_router(input):\n",
        "    # Embed question\n",
        "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
        "    # Compute similarity\n",
        "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
        "    # Return index of most similar prompt\n",
        "    most_similar = prompt_templates[similarity.argmax()]\n",
        "    # Chosen prompt\n",
        "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
        "    return PromptTemplate(template=most_similar)\n",
        "\n",
        "\n",
        "chain = (\n",
        "    {\n",
        "        \"query\": RunnablePassthrough()\n",
        "    }\n",
        "    | RunnableLambda(prompt_router)\n",
        "    | ChatOpenAI()\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain.invoke(\n",
        "    \"What is the speed of light?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "-DuYh1RNxPeV",
        "outputId": "ab0b7435-035a-4faa-84a2-c9799452d3f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PHYSICS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The speed of light in a vacuum is approximately 299,792 kilometers per second (or about 186,282 miles per second).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\n",
        "    \"What is cosine similarity?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "udPmjTgVx9sS",
        "outputId": "70a1ffbf-ea68-4757-89ff-3815a6b60135"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using MATH\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cosine similarity is a measure of similarity between two vectors in a multi-dimensional space. It is often used in machine learning and data mining to compare the similarity between two documents or items based on their content or features.\\n\\nIn mathematical terms, the cosine similarity between two vectors A and B is calculated by taking the dot product of the two vectors and dividing it by the product of their magnitudes. The formula for cosine similarity is:\\n\\ncosine similarity = (A • B) / (||A|| * ||B||)\\n\\nWhere A • B is the dot product of vectors A and B, and ||A|| and ||B|| are the magnitudes of vectors A and B, respectively.\\n\\nThe cosine similarity value ranges from -1 to 1, with 1 indicating that the two vectors are identical, 0 indicating no similarity, and -1 indicating complete dissimilarity. A higher cosine similarity value indicates a higher degree of similarity between the two vectors.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\n",
        "    \"What is the difference between cosine similarity and dot product?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "WJVHTnWF1Ver",
        "outputId": "8abd4492-9be1-4d4f-8399-98a056883574"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PHYSICS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cosine similarity and dot product are both mathematical operations used in linear algebra, but they serve slightly different purposes.\\n\\nThe dot product is a scalar value that measures the similarity between two vectors by taking the cosine of the angle between them and multiplying their magnitudes. It essentially quantifies how much two vectors point in the same direction.\\n\\nCosine similarity, on the other hand, is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. It is a normalized form of the dot product, where the result is scaled to a value between -1 and 1, with 1 indicating perfect similarity and -1 indicating perfect dissimilarity.\\n\\nIn summary, while the dot product quantifies the directional similarity between two vectors in terms of their magnitudes, cosine similarity measures the angle between them to determine their similarity in a normalized manner.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query structuring for metadata filters\n",
        "\n",
        "Many vectorstores contain metadata fields. This makes it possible to filter for specific chunks based on metadata. Let's look at some example metadata we might see in a database of YouTube transcripts."
      ],
      "metadata": {
        "id": "mLtJjdNa2Bwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api pytube -q"
      ],
      "metadata": {
        "id": "138gSKrC-xuE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pytube -q"
      ],
      "metadata": {
        "id": "DDNK3IoT_wy2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "\n",
        "docs = YoutubeLoader.from_youtube_url(\n",
        "    \"https://www.youtube.com/watch?v=pbAd8O1Lvm4\",\n",
        "    add_video_info=False,\n",
        ").load()\n",
        "\n",
        "docs[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zjHgO3t1rhj",
        "outputId": "f1502c8a-380c-4b10-8bc1-2d7ef2ef9ff2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'pbAd8O1Lvm4'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].metadata = {\n",
        "    'source': 'pbAd8O1Lvm4',\n",
        "    'title': 'Self-reflective RAG with LangGraph: Self-RAG and CRAG',\n",
        "    'description': 'Unknown',\n",
        "    'view_count': 11922,\n",
        "    'thumbnail_url': 'https://i.ytimg.com/vi/pbAd8O1Lvm4/hq720.jpg',\n",
        "    'publish_date': '2024-02-07 00:00:00',\n",
        "    'length': 1058,\n",
        "    'author': 'LangChain'\n",
        "}"
      ],
      "metadata": {
        "id": "pX3BmchqCrpA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNL4kCbDC93t",
        "outputId": "44de4b39-ca08-4b14-e704-d77de9cbb6af"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'pbAd8O1Lvm4',\n",
              " 'title': 'Self-reflective RAG with LangGraph: Self-RAG and CRAG',\n",
              " 'description': 'Unknown',\n",
              " 'view_count': 11922,\n",
              " 'thumbnail_url': 'https://i.ytimg.com/vi/pbAd8O1Lvm4/hq720.jpg',\n",
              " 'publish_date': '2024-02-07 00:00:00',\n",
              " 'length': 1058,\n",
              " 'author': 'LangChain'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from typing import Literal, Optional, Tuple\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "class TutorialSearch(BaseModel):\n",
        "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
        "\n",
        "    content_search: str = Field(\n",
        "        ...,\n",
        "        description=\"Similarity search query applied to video transcripts\"\n",
        "    )\n",
        "    title_search: str = Field(\n",
        "        ...,\n",
        "        description= (\n",
        "            \"Alternate version of the content search query to apply to video title.\"\n",
        "            \"Should be succint and only include key words that could be in a video\"\n",
        "            \"title\"\n",
        "        )\n",
        "    )\n",
        "    min_view_count: Optional[int] = Field(\n",
        "        None,\n",
        "        description=\"Minimum view count filter, inclusive. Only use if explicitly specified\"\n",
        "    )\n",
        "    max_view_count: Optional[int] = Field(\n",
        "        None,\n",
        "        description=\"Maximum view count filter, exclusive. Only use if explicitly specified\"\n",
        "    )\n",
        "    earliest_publish_data: Optional[datetime.date] = Field(\n",
        "        None,\n",
        "        description=\"Earliest publish date filter, inclusive. Only use if explicitly specified\"\n",
        "    )\n",
        "    latest_publish_data: Optional[datetime.date] = Field(\n",
        "        None,\n",
        "        description=\"Latest publish date filter, exclusive. Only use if explicitly specified\"\n",
        "    )\n",
        "    min_length_sec: Optional[int] = Field(\n",
        "        None,\n",
        "        description=\"Minimum length filter, inclusive. Only use if explicitly specified\"\n",
        "    )\n",
        "    max_length_sec: Optional[int] = Field(\n",
        "        None,\n",
        "        description=\"Maximum length filter, exclusive. Only use if explicitly specified\"\n",
        "    )\n",
        "\n",
        "    def pretty_print(self) -> None:\n",
        "        for field in self.__fields__:\n",
        "            if getattr(self, field) is not None and getattr(self, field) != getattr(\n",
        "                self.__fields__[field], \"default\", None\n",
        "            ):\n",
        "                print(f\"{field}: {getattr(self, field)}\")"
      ],
      "metadata": {
        "id": "qw7wQ0VXDK2E"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "system = \"\"\"You are an expert at converting user questions into database queries.\n",
        "You have access to a database of tutorial videos about a software library building\n",
        "LLM-powered applications. \\n\n",
        "Given a question, return a database query optimized to retrieve the most relevant\n",
        "results.\n",
        "\n",
        "If there are acronyms or words you are not familiar with, do not try to rephrase\n",
        "them.\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\")\n",
        "    ]\n",
        ")\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "structured_llm = llm.with_structured_output(TutorialSearch)\n",
        "query_analyzer = prompt | structured_llm"
      ],
      "metadata": {
        "id": "Y8bl1mbxFQvl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke(\n",
        "    {\n",
        "        \"question\": \"rag from scratch\"\n",
        "    }\n",
        ").pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wxMiicYHEQR",
        "outputId": "1d5e5b23-edc7-487b-fe18-404679cd61a2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: rag from scratch\n",
            "title_search: rag from scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke(\n",
        "    {\"question\": \"videos on chat langchain published in 2023\"}\n",
        ").pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgTWfMYzHRwC",
        "outputId": "e2ee4923-8bf7-491f-cb36-b10e8ca02ea9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: chat langchain\n",
            "title_search: 2023\n",
            "earliest_publish_data: 2023-01-01\n",
            "latest_publish_data: 2024-01-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke(\n",
        "    {\n",
        "        \"question\": \"videos that are focused on the topic of chat langchain \\\n",
        "        that are published before 2024\"\n",
        "    }\n",
        ").pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnYtxckKHWUQ",
        "outputId": "1e469639-d544-42d0-9f84-3a050611a195"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: chat langchain\n",
            "title_search: chat langchain\n",
            "latest_publish_data: 2024-01-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke(\n",
        "    {\n",
        "        \"question\": \"how to use multi-modal models in an agent, only \\\n",
        "        videos under 5 minutes\"\n",
        "    }\n",
        ").pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV_0Y0l3HYwd",
        "outputId": "0d449d63-c83a-40e0-d16e-1a7de698346c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: multi-modal models agent\n",
            "title_search: multi-modal models agent\n",
            "max_length_sec: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doing this put in various vectorstores"
      ],
      "metadata": {
        "id": "7OTMeQnqHzdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  lark langchain-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4llPUdUnHkU0",
        "outputId": "73b0d042-98d8-4326-e357-9bfb6c0d633e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m102.4/111.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
        "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
        "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
        "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
        "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Toys come alive and have a blast doing so\",\n",
        "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
        "        metadata={\n",
        "            \"year\": 1979,\n",
        "            \"director\": \"Andrei Tarkovsky\",\n",
        "            \"genre\": \"thriller\",\n",
        "            \"rating\": 9.9,\n",
        "        },\n",
        "    ),\n",
        "]\n",
        "vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "Gqsw_310H716"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating our Self-querying retriever"
      ],
      "metadata": {
        "id": "1f1MINOOITW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.query_constructor.schema import AttributeInfo\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"genre\",\n",
        "        description=\"TThe genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
        "        type=\"string or list[string]\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"year\",\n",
        "        description=\"The year the movie was released\",\n",
        "        type=\"integer\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"director\",\n",
        "        description=\"The name of the movie director\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "document_content_description = \"Brief summary of a movie\"\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    llm,\n",
        "    vectorstore,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        ")"
      ],
      "metadata": {
        "id": "sRpBqlxiIRoD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"I want to watch a movie rated higher than 8.5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVBu6xhjI4kQ",
        "outputId": "566e8600-be2f-4854-f334-79ffed773584"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='a813d2c4-b750-4164-aeae-c5e4870b3a81', metadata={'director': 'Andrei Tarkovsky', 'genre': 'thriller', 'rating': 9.9, 'year': 1979}, page_content='Three men walk into the Zone, three men walk out of the Zone'),\n",
              " Document(id='3d1ef6c9-93b6-491f-a97d-71f4617d0261', metadata={'director': 'Satoshi Kon', 'rating': 8.6, 'year': 2006}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"What's a highly rated (above 8.5) science fiction film?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pruls-jpI76s",
        "outputId": "10b7c2cb-1e82-4fa0-9051-8ae6e68741e7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='3d1ef6c9-93b6-491f-a97d-71f4617d0261', metadata={'director': 'Satoshi Kon', 'rating': 8.6, 'year': 2006}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea'),\n",
              " Document(id='a813d2c4-b750-4164-aeae-c5e4870b3a81', metadata={'director': 'Andrei Tarkovsky', 'genre': 'thriller', 'rating': 9.9, 'year': 1979}, page_content='Three men walk into the Zone, three men walk out of the Zone')]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\n",
        "    \"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca_Doh6kJCjF",
        "outputId": "970e950f-6fff-4d6f-c143-8c5c78ea0683"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='50ae8bb8-ff56-479e-a6dc-b0fed09045fe', metadata={'genre': 'animated', 'year': 1995}, page_content='Toys come alive and have a blast doing so')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}